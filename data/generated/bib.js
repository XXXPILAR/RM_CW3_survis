const generatedBibEntries = {
    "9706348": {
        "author": "Stefanini, Matteo and Cornia, Marcella and Baraldi, Lorenzo and Cascianelli, Silvia and Fiameni, Giuseppe and Cucchiara, Rita",
        "doi": "10.1109/TPAMI.2022.3148210",
        "journal": "IEEE Transactions on Pattern Analysis and Machine Intelligence",
        "keywords": "Visualization;Feature extraction;Task analysis;Convolutional neural networks;Additives;Image coding;Training;Image captioning;vision-and-language;deep learning;survey",
        "number": "1",
        "pages": "539-559",
        "title": "From Show to Tell: A Survey on Deep Learning-Based Image Captioning",
        "type": "ARTICLE",
        "volume": "45",
        "year": "2023"
    },
    "Beck2016Visual": {
        "abstract": "Bibiographic data such as collections of scientific articles and citation networks have been studied extensively in information visualization and visual analytics research. Powerful systems have been built to support various types of bibliographic analysis, but they require some training and cannot be used to disseminate the insights gained. In contrast, we focused on developing a more accessible visual analytics system, called SurVis, that is ready to disseminate a carefully surveyed literature collection. The authors of a survey may use our Web-based system to structure and analyze their literature database. Later, readers of the survey can obtain an overview, quickly retrieve specific publications, and reproduce or extend the original bibliographic analysis. Our system employs a set of selectors that enable users to filter and browse the literature collection as well as to control interactive visualizations. The versatile selector concept includes selectors for textual search, filtering by keywords and meta-information, selection and clustering of similar publications, and following citation links. Agreement to the selector is represented by word-sized sparkline visualizations seamlessly integrated into the user interface. Based on an analysis of the analytical reasoning process, we derived requirements for the system. We developed the system in a formative way involving other researchers writing literature surveys. A questionnaire study with 14 visual analytics experts confirms that SurVis meets the initially formulated requirements.",
        "author": "Beck, Fabian and Koch, Sebastian and Weiskopf, Daniel",
        "doi": "10.1109/TVCG.2015.2467757",
        "journal": "IEEE Transactions on Visualization and Computer Graphics",
        "keywords": "type:system, visual_analytics, sparklines, information_retrieval, clustering, literature_browser",
        "number": "01",
        "publisher": "IEEE",
        "series": "TVCG",
        "title": "Visual Analysis and Dissemination of Scientific Literature Collections with {SurVis}",
        "type": "article",
        "url": "http://www.visus.uni-stuttgart.de/uploads/tx_vispublications/vast15-survis.pdf",
        "volume": "22",
        "year": "2016"
    },
    "anderson2016spice": {
        "author": "Anderson, Peter and Fernando, Basura and Johnson, Mark and Gould, Stephen",
        "booktitle": "Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11-14, 2016, Proceedings, Part V 14",
        "organization": "Springer",
        "pages": "382--398",
        "title": "Spice: Semantic propositional image caption evaluation",
        "type": "inproceedings",
        "year": "2016"
    },
    "anderson2018bottom": {
        "author": "Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei",
        "booktitle": "Proceedings of the IEEE conference on computer vision and pattern recognition",
        "pages": "6077--6086",
        "title": "Bottom-up and top-down attention for image captioning and visual question answering",
        "type": "inproceedings",
        "year": "2018"
    },
    "cornia2020meshed": {
        "author": "Cornia, Marcella and Stefanini, Matteo and Baraldi, Lorenzo and Cucchiara, Rita",
        "booktitle": "Proceedings of the IEEE/CVF conference on computer vision and pattern recognition",
        "pages": "10578--10587",
        "title": "Meshed-memory transformer for image captioning",
        "type": "inproceedings",
        "year": "2020"
    },
    "hessel2021clipscore": {
        "author": "Hessel, Jack and Holtzman, Ari and Forbes, Maxwell and Bras, Ronan Le and Choi, Yejin",
        "journal": "arXiv preprint arXiv:2104.08718",
        "title": "Clipscore: A reference-free evaluation metric for image captioning",
        "type": "article",
        "year": "2021"
    },
    "li2020oscar": {
        "author": "Li, Xiujun and Yin, Xi and Li, Chunyuan and Zhang, Pengchuan and Hu, Xiaowei and Zhang, Lei and Wang, Lijuan and Hu, Houdong and Dong, Li and Wei, Furu and others",
        "booktitle": "Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXX 16",
        "organization": "Springer",
        "pages": "121--137",
        "title": "Oscar: Object-semantics aligned pre-training for vision-language tasks",
        "type": "inproceedings",
        "year": "2020"
    },
    "li2021prefix": {
        "author": "Li, Xiang Lisa and Liang, Percy",
        "journal": "arXiv preprint arXiv:2101.00190",
        "title": "Prefix-tuning: Optimizing continuous prompts for generation",
        "type": "article",
        "year": "2021"
    },
    "li2023blip": {
        "author": "Li, Junnan and Li, Dongxu and Savarese, Silvio and Hoi, Steven",
        "booktitle": "International conference on machine learning",
        "organization": "PMLR",
        "pages": "19730--19742",
        "title": "Blip-2: Bootstrapping language-image pre-training with frozen image encoders and large language models",
        "type": "inproceedings",
        "year": "2023"
    },
    "rennie2017self": {
        "author": "Rennie, Steven J and Marcheret, Etienne and Mroueh, Youssef and Ross, Jerret and Goel, Vaibhava",
        "booktitle": "Proceedings of the IEEE conference on computer vision and pattern recognition",
        "pages": "7008--7024",
        "title": "Self-critical sequence training for image captioning",
        "type": "inproceedings",
        "year": "2017"
    },
    "wang2022git": {
        "author": "Wang, Jianfeng and Yang, Zhengyuan and Hu, Xiaowei and Li, Linjie and Lin, Kevin and Gan, Zhe and Liu, Zicheng and Liu, Ce and Wang, Lijuan",
        "journal": "arXiv preprint arXiv:2205.14100",
        "title": "Git: A generative image-to-text transformer for vision and language",
        "type": "article",
        "year": "2022"
    }
};